{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7993914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory (root) to sys.path\n",
    "sys.path.append(os.path.abspath('C:/Users/Acer nitro/Desktop/retinal-vessel-segmentation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e50b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Acer nitro\\AppData\\Local\\Temp\\ipykernel_11516\\2426530392.py\", line 4, in <module>\n",
      "    from torchvision import transforms\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\__init__.py\", line 7, in <module>\n",
      "    from torchvision import models\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\__init__.py\", line 16, in <module>\n",
      "    from . import detection\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\detection\\__init__.py\", line 1, in <module>\n",
      "    from .faster_rcnn import *\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\detection\\faster_rcnn.py\", line 16, in <module>\n",
      "    from .anchor_utils import AnchorGenerator\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py\", line 10, in <module>\n",
      "    class AnchorGenerator(nn.Module):\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py\", line 63, in AnchorGenerator\n",
      "    device: torch.device = torch.device(\"cpu\"),\n",
      "c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py:63: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  device: torch.device = torch.device(\"cpu\"),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a198d",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48dcee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0dccc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRIVE_dataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transforms = transforms\n",
    "        self.images = [img for img in os.listdir(img_dir) if img.endswith('.tif')] # we dont want other filed besides .tif\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.images[index]\n",
    "        image_path = os.path.join(self.img_dir, image_name)\n",
    "\n",
    "        image_base = image_name.split('_')[0]  # \"21\" from \"21_training.tif\"\n",
    "        mask_name = f\"{image_base}_manual1.gif\"\n",
    "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")        \n",
    "            mask = Image.open(mask_path).convert(\"L\")  # Grayscale\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {image_name}: {e}\")\n",
    "            raise e\n",
    "\n",
    "        # Binarize the mask\n",
    "        mask = np.array(mask)\n",
    "        mask = (mask > 0).astype(np.uint8) # must be 0 or 1\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=np.array(image), mask=np.array(mask))\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed4ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "train_data = DRIVE_dataset(\n",
    "    img_dir = \"C:/Users/Acer nitro/Desktop/retinal-vessel-segmentation/data/DRIVE/training/images\",\n",
    "    mask_dir = \"C:/Users/Acer nitro/Desktop/retinal-vessel-segmentation/data/DRIVE/training/1st_manual\",\n",
    "    transforms = ToTensor(),\n",
    "    )\n",
    "\n",
    "test_data = DRIVE_dataset(\n",
    "    img_dir = \"C:/Users/Acer nitro/Desktop/retinal-vessel-segmentation/data/DRIVE/test/images\",\n",
    "    mask_dir= \"C:/Users/Acer nitro/Desktop/retinal-vessel-segmentation/data/DRIVE/test/1st_manual\",\n",
    "    transforms = ToTensor(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63d0a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BATCH_SIZE = 4\n",
    "NO_OF_WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce968007",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=NO_OF_WORKERS,\n",
    "                              #pin_memory= True\n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             num_workers=NO_OF_WORKERS,\n",
    "                             #pin_memory= True, \n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8572c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427eba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(DoubleConv,self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=3, padding = 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size=3, padding = 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True)\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        output = self.double_conv(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,in_channels = 3,out_channels = 1):\n",
    "        super(Unet,self).__init__()\n",
    "        self.enc1 = DoubleConv(in_channels = in_channels ,out_channels =64)\n",
    "        self.enc2 = DoubleConv(in_channels = 64,out_channels = 128)\n",
    "        self.enc3 = DoubleConv(in_channels =128,out_channels =256)\n",
    "        self.enc4 = DoubleConv(in_channels = 256,out_channels = 512)\n",
    "\n",
    "        self.bottle_neck = DoubleConv(in_channels = 512, out_channels= 1024)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "\n",
    "      \n",
    "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(1024, 512)  # concat with skip connection\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(512, 256)  # concat with skip connection\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(256, 128)  # concat with skip connection\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec4 = DoubleConv(128, 64)  # concat with skip connection\n",
    "\n",
    "        # Final output layer\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)  # For binary segmentation (out_channels = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool(x1))\n",
    "        x3 = self.enc3(self.pool(x2))\n",
    "        x4 = self.enc4(self.pool(x3))\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(self.pool(x4))\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up1(x)\n",
    "        x = torch.cat([x, x4], dim=1)\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.dec2(x)\n",
    "\n",
    "        x = self.up3(x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.dec3(x)\n",
    "\n",
    "        x = self.up4(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.dec4(x)\n",
    "\n",
    "        # Output\n",
    "        return self.out_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "010d1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(in_channels = 3, out_channels = 1).to(device = \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),lr = 0.001, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7af01c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d68da181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader : torch.utils.data,\n",
    "               criterion : torch.nn,\n",
    "               optimizer : torch.optim\n",
    "        ):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss ,train_dice = 0,0\n",
    "\n",
    "    for batch ,(X,y) in enumerate(dataloader):\n",
    "        X,y = X.to(device) , y.to(device)\n",
    "        \n",
    "        #1 forward pass\n",
    "        y_pred = model(X)\n",
    "        #2 calculate loss\n",
    "        loss = criterion(y_pred,y)\n",
    "        train_loss += loss.item()\n",
    "        #3 gradient zero\n",
    "        optimizer.zero_grad()\n",
    "        #4 backprop\n",
    "        loss.backward()\n",
    "        #5 step\n",
    "        optimizer.step()\n",
    "\n",
    "        train_dice += dice_score(y_pred,y)\n",
    "    train_loss /= len(dataloader)\n",
    "    train_dice /= len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b10f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model : torch.nn.Module,\n",
    "              dataloader :  torch.utils.data,\n",
    "              criterion : torch.nn):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss,test_dice = 0, 0\n",
    "\n",
    "    for batch,(X,y) in enumerate(dataloader):\n",
    "        X,y = X.to(device),y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = criterion(y_pred,y)\n",
    "        test_loss += loss.item()\n",
    "        test_dice += dice_score(y_pred,y)\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    test_dice /= len(dataloader)\n",
    "\n",
    "    return test_loss,test_dice\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d47c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ddfeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          criterion: torch.nn.Module = nn.BCEWithLogitsLoss(),\n",
    "          epochs: int = 5):\n",
    "    \n",
    "    # Create empty results dictionary to store metrics\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_dice\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_dice\": []\n",
    "    }\n",
    "    \n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Training step\n",
    "        train_loss, train_dice = train_step(model=model,\n",
    "                                            dataloader=train_dataloader,\n",
    "                                            criterion=criterion,\n",
    "                                            optimizer=optimizer)\n",
    "        \n",
    "        # Testing step\n",
    "        test_loss, test_dice = test_step(model=model,\n",
    "                                          dataloader=test_dataloader,\n",
    "                                          criterion=criterion)\n",
    "        \n",
    "        # Print the results for the current epoch\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_dice: {train_dice:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_dice: {test_dice:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_dice\"].append(train_dice)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_dice\"].append(test_dice)\n",
    "\n",
    "    # Return the results dictionary after training\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device setup (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Recreate an instance of Unet model\n",
    "model_0 = Unet().to(device)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "start_time = timer()\n",
    "\n",
    "# Train model_0\n",
    "model_0_results = train(model=model_0, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        criterion=criterion, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time - start_time:.3f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
