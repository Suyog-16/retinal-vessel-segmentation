{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e50b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Acer nitro\\AppData\\Local\\Temp\\ipykernel_4976\\250570479.py\", line 4, in <module>\n",
      "    from torchvision import transforms\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\__init__.py\", line 7, in <module>\n",
      "    from torchvision import models\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\__init__.py\", line 16, in <module>\n",
      "    from . import detection\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\detection\\__init__.py\", line 1, in <module>\n",
      "    from .faster_rcnn import *\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\detection\\faster_rcnn.py\", line 16, in <module>\n",
      "    from .anchor_utils import AnchorGenerator\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py\", line 10, in <module>\n",
      "    class AnchorGenerator(nn.Module):\n",
      "  File \"c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py\", line 63, in AnchorGenerator\n",
      "    device: torch.device = torch.device(\"cpu\"),\n",
      "c:\\Users\\Acer nitro\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py:63: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  device: torch.device = torch.device(\"cpu\"),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import PIL as Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a198d",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dccc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRIVE_dataset(Dataset):\n",
    "    def __init__(self,img_dir,mask_dir,transforms = None, mask_transfrom = None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transforms = transforms\n",
    "        self.mask_transform = mask_transfrom\n",
    "        self.images = os.listdir(img_dir)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.images[index]\n",
    "        image_path = os.path.join(self.img_dir,image_name)\n",
    "        mask_path = os.path.join(self.mask_dir,image_name) # considering that masks also have the same name\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")        \n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "\n",
    "        return image,mask\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ed4ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "train_data = DRIVE_dataset(\n",
    "    img_dir = \"C:/Users/Acer nitro/Desktop/retinal-vessel-segmentation/data/DRIVE/training/images\",\n",
    "    mask_dir = \"C:/Users/Acer nitro/Desktop/retinal-vessel-segmentation/data/DRIVE/training/mask\",\n",
    "    transforms = ToTensor(),\n",
    "    mask_transfrom = None\n",
    "    )\n",
    "\n",
    "test_data = DRIVE_dataset(\n",
    "    img_dir = \"C:/Users/Acer nitro/Desktop/retinal-vessel-segmentation/data/DRIVE/test/images\",\n",
    "    mask_dir= \"C:/Users/Acer nitro/Desktop/retinal-vessel-segmentation/data/DRIVE/test/mask\",\n",
    "    transforms = ToTensor(),\n",
    "    mask_transfrom= None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63d0a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BATCH_SIZE = 4\n",
    "NO_OF_WORKERS = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce968007",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data,batch_size=BATCH_SIZE,num_workers=NO_OF_WORKERS,shuffle=True)\n",
    "test_dataloader = DataLoader(test_data,batch_size=BATCH_SIZE,num_workers=NO_OF_WORKERS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db8572c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "427eba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(DoubleConv,self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=3, padding = 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=3, padding = 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True)\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        output = self.double_conv(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,in_channels = 3,out_channels = 1):\n",
    "        super(Unet,self).__init__()\n",
    "        self.enc1 = DoubleConv(in_channels = in_channels ,out_channels =64)\n",
    "        self.enc2 = DoubleConv(in_channels = 64,out_channels = 128)\n",
    "        self.enc3 = DoubleConv(in_channels =128,out_channels =256)\n",
    "        self.enc4 = DoubleConv(in_channels = 256,out_channels = 512)\n",
    "\n",
    "        self.bottle_neck = DoubleConv(in_channels = 512, out_channels= 1024)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "\n",
    "      \n",
    "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(1024, 512)  # concat with skip connection\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(512, 256)  # concat with skip connection\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(256, 128)  # concat with skip connection\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec4 = DoubleConv(128, 64)  # concat with skip connection\n",
    "\n",
    "        # Final output layer\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)  # For binary segmentation (out_channels = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool(x1))\n",
    "        x3 = self.enc3(self.pool(x2))\n",
    "        x4 = self.enc4(self.pool(x3))\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(self.pool(x4))\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up1(x)\n",
    "        x = torch.cat([x, x4], dim=1)\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.dec2(x)\n",
    "\n",
    "        x = self.up3(x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.dec3(x)\n",
    "\n",
    "        x = self.up4(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.dec4(x)\n",
    "\n",
    "        # Output\n",
    "        return self.out_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "010d1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(in_channels = 3, out_channels = 1).to(device = \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d68da181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader : torch.utils.data,\n",
    "               criterion : torch.nn,\n",
    "               optimizer : torch.optim\n",
    "        ):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss ,train_dice = 0,0\n",
    "\n",
    "    for batch ,(X,y) in enumerate(dataloader):\n",
    "        X,y = X.to(device) , y.to(device)\n",
    "        \n",
    "        #1 forward pass\n",
    "        y_pred = model(X)\n",
    "        #2 calculate loss\n",
    "        loss = criterion(y_pred,y)\n",
    "        train_loss += loss.item()\n",
    "        #3 gradient zero\n",
    "        optimizer.zero_grad()\n",
    "        #4 backprop\n",
    "        loss.backwards()\n",
    "        #5 step\n",
    "        optimizer.step()\n",
    "\n",
    "        train_dice = dice_score(y_pred,y)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_dice /= len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b10f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model : torch.nn.Module,\n",
    "              dataloader :  torch.utils.data,\n",
    "              criterion : torch.nn):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss,test_dice = 0, 0\n",
    "\n",
    "    for batch,(X,y) in enumerate(dataloader):\n",
    "        X,y = X.to(device),y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = criterion(y_pred,y)\n",
    "        test_loss += loss.item()\n",
    "        test_dice += dice_score(y_pred,y)\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    test_dice /= len(dataloader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ddfeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
